# 阶段 2 · 项目 2
## 带记忆的会议记录助手
目标：上传一段 5 分钟会议录音 → 自动输出 3 行摘要 → 支持后续追问“谁负责预算？”→ 助手能准确回答，实现“语音转写 + 向量记忆 + 多轮追问”完整闭环。

# 涉及技术要点：
1. 录音文件：Whisper API 转写（speaker-diarization 可选）
2. 文字切片： OpenAI Embedding
3. Chroma向量库存储（=长期记忆）
4. 大模型生成摘要 & 回答追问： LangChain RetrievalQA + ConversationBufferMemory 


# 成果体验
```
$ python meeting_agent.py
【1】上传录音: meeting.wav
【2】正在转写... 完成（5:12）
【3】生成摘要:
1. 产品 9 月上线 MVP，由张三负责。
2. 预算 20 万，已审批。
3. 下周三（6-12）14:00 二次评审。

【4】进入追问模式（输入 q 退出）
> 谁负责预算？
Answer: 李四负责预算，并在会议纪要中确认已审批通过。

> 上线时间能否提前？
Answer: 会议中未讨论提前上线，仅明确 9 月发布 MVP。
```

# 环境依赖
```
pip install openai langchain langchain-community chromadb tiktoken soundfile
# Whisper 使用官方 openai-whisper 本地版（免费）或者可以换其他可直接调用「DeepSeek-R1 / 飞书妙记 / 腾讯会议转写」等 API，逻辑相同
pip install openai-whisper
```

# 关键知识点
1. Whisper language="zh"
- 显式指定中文，减少识别错误；word_timestamps=False 提速 30%。
2. RecursiveCharacterTextSplitter
- 按 300 字符滑窗切片，既保持句子完整，又适配 Embedding 长度。
3. Chroma persist_directory
- 向量库落盘，下次启动无需重复转写，实现“跨会话持久记忆”。
4. ConversationalRetrievalChain
- 把“向量检索”与“对话记忆”合二为一，追问时自动携带历史，防止重复检索。
5. 摘要 prompt 设计
强制“三句话+关键结论/待办”，让输出可直接贴邮件，减少人工二次编辑。

# 知识点详解：向量数据库
## 向量数据库（Vector Database）用于[存储](#向量数据库的搜索算法)、[索引](#向量数据库的索引算法)和[检索](#向量数据库的搜索算法)高维向量，这些向量通常来自文本、图像、音频等非结构化数据的 embedding（嵌入）
## [<u>*Embedding（嵌入）*</u>](#embedding的数学原理)： 是把离散的内容变量（文本、图片、音频等）转换成连续的高维连续向量空间的技术。转换后更有相关性的内容在映射到同一向量空间后向量距离越近。生成的向量就叫做<u>***“嵌入向量”***</u>
   - 例如：“猫”和“狗”在语义上更接近，而“猫”和“汽车”则差的很远。Embedding将它们映射到同一向量空间中，使得：
     - 猫 → [0.12, 0.98, 0.33, ...]
     - 狗 → [0.10, 0.95, 0.30, ...]
     - 汽车 → [0.88, 0.02, 0.11, ...]
   - 猫和狗的向量距离很近，而猫和汽车很远
 - Embedding技术员是机器从处理文字到理解语义相似的重要基础技术，在做语义搜索、推荐系统、RAG检索增强生成、和相似度匹配等领域十分重要
- *而向量数据库就是用来存这些embedding*,可以自动把文本转换成向量并存储

## 向量数据库的核心能力
1. 高维向量存储
- 每条数据包含：
  - 向量（embedding）
  - 元数据（文本、标签、时间等）
  - ID
2. 相似度搜索（ANN）
- 常用距离：
  - 余弦相似度
  - 欧氏距离
  - 点积
3. 高效索引结构
- 如：
  - HNSW（分层小世界图）
  - IVF（倒排文件）
  - PQ（乘积量化）
- *这些结构让百万级向量检索毫秒级完成。*
4. 元数据过滤
- 例如：
  - 找“关于金融的文档”，但只要“2024 年之后的”。
5. 分布式能力
- 支持海量数据、水平扩展。




# 进阶拓展：
1. 说话人分离：Whisper 最新版支持 --diarize，需额外装 pyannote.audio，可把“谁说了什么”也写进向量元数据，追问“张三在会上的观点？”精准定位。
2. 可视化播放器：用 streamlit 做一个上传页面 + 波形图点击跳转文字，练习“音频-文本对齐”前端。
3. 自动待办提取：在摘要链后加一步 LLMChain 用正则抽取“任务/负责人/截止日”，生成可导出的 .csv 或飞书多维表格 。
4. 实时会议模式：接入腾讯会议/Zoom 的录制 webhook，一旦会议结束自动触发转写→摘要→推送到飞书群，实现“会议结束 1 分钟拿到纪要”。
5. 成本优化：把 Embedding 模型换成 text2vec-base 本地版，Whisper 用 tiny 模型，适合内网零 API 费用场景。




## Embedding - 向量数据库 -LLM完整链条
1. Embedding 模型：理解语义 把文本转成向量。<u>“语义编码器”</u>
2. 向量数据库：记忆语义 存储向量并提供快速相似度检索。<u>“语义记忆库”</u>
3. LLM：生成回答 根据检索结果生成最终答案。<u>“语义推理器”</u>

### Embedding的数学原理
1. 核心思想：[从**分布假说(Distributional Hypothesis)**到**嵌入层共现矩阵**到**神经网络模型训练**](https://www.xiaocaicai.com/2025/10/embedding%E6%A8%A1%E5%9E%8B%E7%A9%B6%E7%AB%9F%E6%98%AF%E5%A6%82%E4%BD%95%E7%82%BC%E6%88%90%E7%9A%84%EF%BC%9F/) 
   - *一个词的意义，由其所处的上下文（Context）来定义。*
   - 通过学习海量数据中的上下文关系，将抽象的关系量化并压缩到一个数学向量中。例如两个词汇的上下文相似度很高，那么模型有理由认为它们在语义上是高度相关或者类似的。
2. *Embedding 层*在神经网络本质上是一个可训练的查找表矩阵,每个词的向量就是矩阵的一行。
   - 训练方式：
     - 输入 token → 查表得到向量
     - 向量进入神经网络
     - 通过损失函数（如预测下一个词）反向传播
     - Embedding 矩阵被更新，逐渐学到语义结构
3. <u>***TODO***</u>

### 向量数据库的储存和数据结构
<u>***TODO***</u>

### 向量数据库的索引算法
<u>***TODO***</u>

### 向量数据库的搜索算法
<u>***TODO***</u>

### RAG系统框架